# üêò Big Data All-in-One ‚Äî Docker

Environnement complet mono-conteneur pour un **cours Big Data**.

| Composant | Version | R√¥le |
|-----------|---------|------|
| **HDFS** | Hadoop 3.3.6 | Syst√®me de fichiers distribu√© (1 NameNode + 1 DataNode) |
| **YARN** | Hadoop 3.3.6 | Gestionnaire de ressources cluster |
| **MapReduce** | Hadoop 3.3.6 | Mod√®le de traitement distribu√© |
| **Hive** | 3.1.3 | SQL sur Hadoop (HQL) |
| **Tez** | 0.10.3 | Moteur DAG (remplace MR pour Hive) |
| **Sqoop** | 1.4.7 | Import/export SGBDR ‚Üî HDFS |
| **Zeppelin** | 0.11.1 | Notebook interactif (SQL, shell‚Ä¶) |

---

## üöÄ D√©marrage rapide

### √âtape 1 : Pr√©paration de l'environnement

```bash
cd ~
sudo rm -Rf ~/hadoop-tp00

#### Ici, on va simplement cloner le projet :
git clone https://github.com/crystalloide/hadoop-tp00

cd ~/hadoop-tp00
```
```bash
# 1. Construire l'image (premi√®re fois : ~10-15 min)
docker compose build

# 2. Lancer le cluster
docker compose up -d

# 3. Suivre les logs de d√©marrage (<CTRL>+<C> pour sortir)
docker compose logs -f bigdata

# 4. Regarder les ports √† l'√©coute :
netstat -anl | grep -E '9870|8088|19888|8080|10000'

```

Le cluster est pr√™t quand vous voyez `‚úÖ Cluster Big Data pr√™t !`

---

## üåê Interfaces Web

| Interface | URL | Lancer l'affichage |   
|-----------|-----|--------------------|
| HDFS NameNode | http://localhost:9870 | firefox http://localhost:9870 |
| YARN ResourceManager | http://localhost:8088 | firefox http://localhost:8088 |
| MapReduce History | http://localhost:19888 | firefox http://localhost:19888 |
| Zeppelin Notebooks | http://localhost:8080 | firefox http://localhost:8080 |

---

## üíª Commandes essentielles

### Ouvrir un terminal dans le conteneur
```bash
docker exec -it bigdata-cluster bash
```

### HDFS
```bash
# Lister la racine
hdfs dfs -ls /

# Supprimer / Cr√©er un r√©pertoire
hdfs dfs -rm -r /monrepertoire
hdfs dfs -mkdir /monrepertoire

# Uploader un fichier
rm monFichier.csv
echo "hadoop,hive,hadoop,tez,hive" > monFichier.csv
hdfs dfs -put monFichier.csv /monrepertoire/

# Afficher un fichier
hdfs dfs -cat /monrepertoire/monFichier.csv
```

### MapReduce ‚Äî WordCount (exemple classique)
```bash
# Cr√©er un fichier test
echo "hadoop hive hadoop tez hive hive" > /tmp/texte.txt
hdfs dfs -mkdir /input
hdfs dfs -put /tmp/texte.txt /input/

# Lancer le job WordCount
hdfs dfs -rm -r /output
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
  wordcount /input /output

# Voir le r√©sultat
hdfs dfs -cat /output/part-r-00000
```

### Hive via Beeline (HiveServer2)
```bash

echo "id,produit,montant" > ventes.csv && for i in {1..10}; do echo "$i,Produit_$(printf "%02d" $i),$((10 + RANDOM % 90)).$((RANDOM % 99))" >> ventes.csv; done
hdfs dfs -put ventes.csv /input/ventes.csv
hdfs dfs -cat hdfs://bigdata-node:9000/input/ventes.csv

beeline -u "jdbc:hive2://localhost:10000" -n root

# Dans Beeline :
set hive.execution.engine=mr;

SHOW DATABASES;
CREATE DATABASE cours;
USE cours;

CREATE TABLE ventes (
  id     INT,
  produit STRING,
  montant DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

ALTER TABLE cours.ventes SET TBLPROPERTIES ("skip.header.line.count"="1");

LOAD DATA INPATH '/input/ventes.csv' INTO TABLE cours.ventes;
SELECT produit, SUM(montant) FROM cours.ventes GROUP BY produit;
```

### Sqoop ‚Äî Importer depuis MySQL
```bash
# Lister les bases MySQL distantes
sqoop list-databases \
  --connect jdbc:mysql://mysql-host:3306/ \
  --username root --password secret

# Importer une table vers HDFS
sqoop import \
  --connect jdbc:mysql://mysql-host:3306/mabase \
  --username root --password secret \
  --table matable \
  --target-dir /user/root/matable \
  --num-mappers 1

# Importer directement dans Hive
sqoop import \
  --connect jdbc:mysql://mysql-host:3306/mabase \
  --username root --password secret \
  --table matable \
  --hive-import \
  --hive-table cours.matable \
  --num-mappers 1
```

### Zeppelin
Acc√©der √† http://localhost:8080 et cr√©er un nouveau notebook.  
Utiliser l'interpr√©teur `%hive` pour ex√©cuter du HQL directement dans le navigateur.

---

## ‚öôÔ∏è Configuration

| Fichier | Description |
|---------|-------------|
| `config/hadoop/core-site.xml` | URI du NameNode |
| `config/hadoop/hdfs-site.xml` | R√©pertoires HDFS, r√©plication |
| `config/hadoop/mapred-site.xml` | Framework MR, m√©moire Map/Reduce |
| `config/hadoop/yarn-site.xml` | Ressources YARN |
| `config/hive/hive-site.xml` | Metastore Derby, moteur Tez |
| `config/tez/tez-site.xml` | M√©moire DAG, chemin HDFS Tez |
| `config/zeppelin/zeppelin-site.xml` | Port, acc√®s anonyme |

### Ajuster la m√©moire
Modifier `yarn.nodemanager.resource.memory-mb` dans `yarn-site.xml` et `mem_limit` dans `docker-compose.yml` selon la RAM disponible :

| RAM machine | Recommand√© |
|-------------|-----------|
| 4 Go | 3 Go (mem_limit: 3g) |
| 8 Go | 5 Go (mem_limit: 5g) |
| 16 Go | 8 Go (mem_limit: 8g) |

---

## üõë Arr√™t et nettoyage

```bash
# Arr√™ter le cluster (volumes conserv√©s)
docker compose down

# Arr√™ter ET supprimer les volumes (reset complet)
docker compose down -v
```

---

## ‚ö†Ô∏è Notes importantes

- **Metastore Derby** : embarqu√© dans Hive, parfait pour un cours. Limit√© √† une seule connexion simultan√©e. Remplacer par MySQL pour un usage multi-utilisateurs.
- **Pas de Kerberos** : la s√©curit√© est d√©sactiv√©e pour simplifier l'apprentissage.
- **Mode pseudo-distribu√©** : un seul n≈ìud joue les r√¥les NameNode et DataNode simultan√©ment.
- **Tez** : l'upload du tarball sur HDFS se fait automatiquement au premier d√©marrage.
