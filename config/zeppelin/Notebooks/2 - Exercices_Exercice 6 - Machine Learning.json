{"paragraphs":[{"text":"%md\n\n## Bienvenue dans ce sixième exercice\n\nL'objectif de ce sixième exercice est de montrer un exemple d'utilisation de l'API de machine learning de Spark.\n\nNous allons tenter de créer un modèle à partir d'un algorithme random forest","dateUpdated":"2020-10-05T10:59:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Bienvenue dans ce sixième exercice</h2>\n<p>L&rsquo;objectif de ce sixième exercice est de montrer un exemple d&rsquo;utilisation de l&rsquo;API de machine learning de Spark.</p>\n<p>Nous allons tenter de créer un modèle à partir d&rsquo;un algorithme random forest</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895556102_-84261611","id":"20180411-203501_1814194885","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46551"},{"text":"%spark\n\n// Imports ML\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n"}]},"apps":[],"jobName":"paragraph_1601895556102_-84261611","id":"20180411-203648_1689689423","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46552"},{"text":"%spark\n\n// Q1 - Chargez le fichier de données \"/data/mllib/sample_libsvm_data.txt\" qui est au format \"libsvm\", un format de vecteur spécifique au machine learning.\nval data = spark.read.format(\"libsvm\").load(\"/data/mllib/sample_libsvm_data.txt\")\ndata.show","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"data: org.apache.spark.sql.DataFrame = [label: double, features: vector]\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(692,[127,128,129...|\n|  1.0|(692,[158,159,160...|\n|  1.0|(692,[124,125,126...|\n|  1.0|(692,[152,153,154...|\n|  1.0|(692,[151,152,153...|\n|  0.0|(692,[129,130,131...|\n|  1.0|(692,[158,159,160...|\n|  1.0|(692,[99,100,101,...|\n|  0.0|(692,[154,155,156...|\n|  0.0|(692,[127,128,129...|\n|  1.0|(692,[154,155,156...|\n|  0.0|(692,[153,154,155...|\n|  0.0|(692,[151,152,153...|\n|  1.0|(692,[129,130,131...|\n|  0.0|(692,[154,155,156...|\n|  1.0|(692,[150,151,152...|\n|  0.0|(692,[124,125,126...|\n|  0.0|(692,[152,153,154...|\n|  1.0|(692,[97,98,99,12...|\n|  1.0|(692,[124,125,126...|\n+-----+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1601895556102_-84261611","id":"20180411-203655_2076726627","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46553"},{"text":"%md\n\nLe but de cet exercice va être de prédire créer un modèle capable de prédire la varible \"label\" en fonction du vecteur \"feature\"\n\nLa colonne feature est déjà formaté en tant que vecteur, un objet mathématiques énormément utilisé par les algorithme de machine learning.\n\nAvant d'appliquer l'algorithme de machine learning sur nos données, il est nécessaire de les indexés.","dateUpdated":"2020-10-05T10:59:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Le but de cet exercice va être de prédire créer un modèle capable de prédire la varible &ldquo;label&rdquo; en fonction du vecteur &ldquo;feature&rdquo;</p>\n<p>La colonne feature est déjà formaté en tant que vecteur, un objet mathématiques énormément utilisé par les algorithme de machine learning.</p>\n<p>Avant d&rsquo;appliquer l&rsquo;algorithme de machine learning sur nos données, il est nécessaire de les indexés.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-211708_1322653657","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46554"},{"text":"%spark\n\n// Il est nécessaire d'indexer la variable que l'on souhaite prédire. Pour cela nous créons un StringIndexer.\n\n// Q2 - Renseignez la colonne \"label\" comme input du StringIndexer\n\nval labelIndexer = new StringIndexer()\n  .setInputCol(\"label\")\n  .setOutputCol(\"indexedLabel\")\n  .fit(data) // fit permet d'appliquer l'indexation sur nos données\n  \n// // Le vecteur \"feature \" est la donnée d'entrée permettant de déduire la variable à prédire.\n// Q2 bis - Créez un VectorIndexer à partir de la colonne \"features\"\nval featureIndexer = new VectorIndexer()\n  .setInputCol(\"features\")\n  .setOutputCol(\"indexedFeatures\")\n  .fit(data) // fit permet d'appliquer l'indexation sur nos données","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"labelIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_f0595d30f8be\nfeatureIndexer: org.apache.spark.ml.feature.VectorIndexerModel = vecIdx_691337382482\n"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-203900_36988933","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46555"},{"text":"%md\n\nNous divisons nos données de test 2 parties. Le But est d'avoir un échantillon pour entrainer le model et un échantillon différent pour tester le modèle nouvellement créé.\n","dateUpdated":"2020-10-05T10:59:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Nous divisons nos données de test 2 parties. Le But est d&rsquo;avoir un échantillon pour entrainer le model et un échantillon différent pour tester le modèle nouvellement créé.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-204433_1549892838","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46556"},{"text":"%spark\n\n// Q3 - A l'aide de la fonction randomSplit, divisez le jeu de donnée d'input en deux échantillons avec un rapport de 70/30.\n// La fonction randomSplit prend en paramètre un \"Array(x, y)\" où x et y sont nos deux pourcentages (entre 0 et 1)\nval Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"trainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\n"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-204230_1610216918","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46557"},{"text":"%spark\n\n// Il est temps de définir notre modèle.\nval rf = new RandomForestClassifier()\n  .setLabelCol(\"indexedLabel\")\n  .setFeaturesCol(\"indexedFeatures\")\n  .setNumTrees(10)\n  \n// Il est nécessaire de créer un convertisseur entre les labels indexés et les labels originaux.\nval labelConverter = new IndexToString()\n  .setInputCol(\"prediction\")\n  .setOutputCol(\"predictedLabel\")\n  .setLabels(labelIndexer.labels)","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_a7a75f9a3cd1\nlabelConverter: org.apache.spark.ml.feature.IndexToString = idxToStr_0b0826d88bcf\n"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-204625_2010530281","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46558"},{"text":"%md\n\nNous utilisons le concept de Pipeline.\nUn Pipeline permet de créer un workflow de l'ensemble de nos transformations/paramètres/algorithme.\n\nUne fois définis il suffit d'appeler notre pipeline pour entrainer notre modèle.\n\nhttps://spark.apache.org/docs/latest/ml-pipeline.html\n","dateUpdated":"2020-10-05T10:59:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Nous utilisons le concept de Pipeline.<br/>Un Pipeline permet de créer un workflow de l&rsquo;ensemble de nos transformations/paramètres/algorithme.</p>\n<p>Une fois définis il suffit d&rsquo;appeler notre pipeline pour entrainer notre modèle.</p>\n<p><a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html\">https://spark.apache.org/docs/latest/ml-pipeline.html</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-215620_748267939","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46559"},{"text":"%spark\n\n// Q4 - Complétez les stages du pipeline avec les objets précédement créés : labelIndexer, featureIndexer, rf, labelConverter.\nval pipeline = new Pipeline()\n  .setStages(Array(labelIndexer, featureIndexer, rf, labelConverter))","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"pipeline: org.apache.spark.ml.Pipeline = pipeline_e6393e9969a0\n"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-205254_1044638856","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46560"},{"text":"%spark\n\n// Q5 - A partir du pipeline, entraînez un modèle à partir du jeu de donnée de \"training\".\nval model = pipeline.fit(trainingData)","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"model: org.apache.spark.ml.PipelineModel = pipeline_e6393e9969a0\n"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-205307_1124286717","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46561"},{"text":"%spark\n\n// Q6 - Faites vos premières prédictions. Pour cela utilisez la méthode \".transform(testData)\" appliqué au model précédement créé.\nval predictions = model.transform(testData)\npredictions.show\n","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"predictions: org.apache.spark.sql.DataFrame = [label: double, features: vector ... 6 more fields]\n+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n|label|            features|indexedLabel|     indexedFeatures|rawPrediction|probability|prediction|predictedLabel|\n+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\n|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[125,126,127...|         1.0|(692,[125,126,127...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[129,130,131...|         1.0|(692,[129,130,131...|    [1.0,9.0]|  [0.1,0.9]|       1.0|           0.0|\n|  0.0|(692,[151,152,153...|         1.0|(692,[151,152,153...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[152,153,154...|         1.0|(692,[152,153,154...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[155,156,180...|         1.0|(692,[155,156,180...|   [0.0,10.0]|  [0.0,1.0]|       1.0|           0.0|\n|  0.0|(692,[181,182,183...|         1.0|(692,[181,182,183...|    [3.0,7.0]|  [0.3,0.7]|       1.0|           0.0|\n|  0.0|(692,[234,235,237...|         1.0|(692,[234,235,237...|    [5.0,5.0]|  [0.5,0.5]|       0.0|           1.0|\n|  1.0|(692,[97,98,99,12...|         0.0|(692,[97,98,99,12...|    [8.0,2.0]|  [0.8,0.2]|       0.0|           1.0|\n|  1.0|(692,[100,101,102...|         0.0|(692,[100,101,102...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n|  1.0|(692,[123,124,125...|         0.0|(692,[123,124,125...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n|  1.0|(692,[125,126,127...|         0.0|(692,[125,126,127...|    [9.0,1.0]|  [0.9,0.1]|       0.0|           1.0|\n|  1.0|(692,[126,127,128...|         0.0|(692,[126,127,128...|   [10.0,0.0]|  [1.0,0.0]|       0.0|           1.0|\n+-----+--------------------+------------+--------------------+-------------+-----------+----------+--------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-205322_1904906590","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46562"},{"text":"%spark\n\n// Q7 - A l'aide d'un select, n'affichez unique que les colonnes features, label et predictedLabel.\npredictions.select(\"features\", \"label\", \"predictedLabel\").show","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-----+--------------+\n|            features|label|predictedLabel|\n+--------------------+-----+--------------+\n|(692,[123,124,125...|  0.0|           0.0|\n|(692,[123,124,125...|  0.0|           0.0|\n|(692,[123,124,125...|  0.0|           0.0|\n|(692,[124,125,126...|  0.0|           0.0|\n|(692,[124,125,126...|  0.0|           0.0|\n|(692,[125,126,127...|  0.0|           0.0|\n|(692,[126,127,128...|  0.0|           0.0|\n|(692,[126,127,128...|  0.0|           0.0|\n|(692,[129,130,131...|  0.0|           0.0|\n|(692,[151,152,153...|  0.0|           0.0|\n|(692,[152,153,154...|  0.0|           0.0|\n|(692,[155,156,180...|  0.0|           0.0|\n|(692,[181,182,183...|  0.0|           0.0|\n|(692,[234,235,237...|  0.0|           1.0|\n|(692,[97,98,99,12...|  1.0|           1.0|\n|(692,[100,101,102...|  1.0|           1.0|\n|(692,[123,124,125...|  1.0|           1.0|\n|(692,[124,125,126...|  1.0|           1.0|\n|(692,[125,126,127...|  1.0|           1.0|\n|(692,[126,127,128...|  1.0|           1.0|\n+--------------------+-----+--------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1601895556103_-84646360","id":"20180411-205409_1673514639","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46563"},{"text":"%md\n\nIl est maintenant nécessaire de calculer la performance de notre modèle.\n","dateUpdated":"2020-10-05T10:59:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Il est maintenant nécessaire de calculer la performance de notre modèle.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895556104_-86570104","id":"20180411-220525_402410603","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46564"},{"text":"// Grâce à un évaluator il est possible de calculer la précision de notre modèle\nval evaluator = new MulticlassClassificationEvaluator()\n  .setLabelCol(\"indexedLabel\")\n  .setPredictionCol(\"prediction\")\n  .setMetricName(\"accuracy\")\nval accuracy = evaluator.evaluate(predictions)\nprintln(s\"Test Error = ${(1.0 - accuracy)}\")\n\nval rfModel = model.stages(2).asInstanceOf[RandomForestClassificationModel]\nprintln(s\"Learned classification forest model:\\n ${rfModel.toDebugString}\")","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_5651bfbe254a\naccuracy: Double = 0.96875\nTest Error = 0.03125\nrfModel: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel (uid=rfc_a7a75f9a3cd1) with 10 trees\nLearned classification forest model:\n RandomForestClassificationModel (uid=rfc_a7a75f9a3cd1) with 10 trees\n  Tree 0 (weight 1.0):\n    If (feature 412 <= 0.0)\n     If (feature 443 in {0.0})\n      Predict: 0.0\n     Else (feature 443 not in {0.0})\n      Predict: 1.0\n    Else (feature 412 > 0.0)\n     Predict: 1.0\n  Tree 1 (weight 1.0):\n    If (feature 463 <= 0.0)\n     If (feature 545 <= 43.0)\n      Predict: 1.0\n     Else (feature 545 > 43.0)\n      If (feature 356 <= 0.0)\n       Predict: 0.0\n      Else (feature 356 > 0.0)\n       Predict: 1.0\n    Else (feature 463 > 0.0)\n     Predict: 0.0\n  Tree 2 (weight 1.0):\n    If (feature 540 <= 0.0)\n     If (feature 603 <= 253.0)\n      Predict: 0.0\n     Else (feature 603 > 253.0)\n      Predict: 1.0\n    Else (feature 540 > 0.0)\n     If (feature 405 <= 173.0)\n      Predict: 1.0\n     Else (feature 405 > 173.0)\n      Predict: 0.0\n  Tree 3 (weight 1.0):\n    If (feature 328 <= 0.0)\n     If (feature 350 <= 0.0)\n      Predict: 1.0\n     Else (feature 350 > 0.0)\n      Predict: 0.0\n    Else (feature 328 > 0.0)\n     Predict: 1.0\n  Tree 4 (weight 1.0):\n    If (feature 429 <= 0.0)\n     If (feature 206 in {0.0})\n      Predict: 0.0\n     Else (feature 206 not in {0.0})\n      Predict: 1.0\n    Else (feature 429 > 0.0)\n     Predict: 1.0\n  Tree 5 (weight 1.0):\n    If (feature 462 in {1.0,3.0,6.0,13.0,14.0,15.0,16.0})\n     Predict: 0.0\n    Else (feature 462 not in {1.0,3.0,6.0,13.0,14.0,15.0,16.0})\n     If (feature 622 in {5.0})\n      Predict: 0.0\n     Else (feature 622 not in {5.0})\n      Predict: 1.0\n  Tree 6 (weight 1.0):\n    If (feature 512 <= 0.0)\n     If (feature 545 <= 2.0)\n      Predict: 1.0\n     Else (feature 545 > 2.0)\n      Predict: 0.0\n    Else (feature 512 > 0.0)\n     Predict: 1.0\n  Tree 7 (weight 1.0):\n    If (feature 512 <= 0.0)\n     Predict: 0.0\n    Else (feature 512 > 0.0)\n     Predict: 1.0\n  Tree 8 (weight 1.0):\n    If (feature 462 in {1.0,2.0,3.0,5.0,7.0,14.0,15.0,16.0})\n     Predict: 0.0\n    Else (feature 462 not in {1.0,2.0,3.0,5.0,7.0,14.0,15.0,16.0})\n     If (feature 324 <= 253.0)\n      Predict: 1.0\n     Else (feature 324 > 253.0)\n      Predict: 0.0\n  Tree 9 (weight 1.0):\n    If (feature 427 <= 0.0)\n     If (feature 517 <= 0.0)\n      If (feature 323 <= 37.0)\n       Predict: 1.0\n      Else (feature 323 > 37.0)\n       Predict: 0.0\n     Else (feature 517 > 0.0)\n      Predict: 0.0\n    Else (feature 427 > 0.0)\n     Predict: 1.0\n\n"}]},"apps":[],"jobName":"paragraph_1601895556104_-86570104","id":"20180409-203032_2124036389","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46565"},{"text":"%sh\n","dateUpdated":"2020-10-05T10:59:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1601895556104_-86570104","id":"20180411-203332_560406963","dateCreated":"2020-10-05T10:59:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:46566"}],"name":"2 - Exercices/Exercice 6 - Machine Learning","id":"2FN1VDMMS","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}