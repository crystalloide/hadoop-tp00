{
  "metadata": {
    "name": "Exercice C - Prediction de Clics sur des Publicites: Analyse de Donnees et Regression Logistique",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n\r\n### Prédiction de Clics sur des Publicités: Analyse de Données et Régression Logistique :\r\n\r\nCe notebook reproduit l\u0027analyse de données et la prédiction de clics sur des publicités présentées dans la vidéo de Smart Data Camp. Nous allons créer un modèle de régression logistique qui prédit si un utilisateur cliquera sur une publicité en fonction de ses caractéristiques.\r\n\r\n#### Problématique :\r\n\r\nDans ce projet, nous allons travailler sur un ensemble de données indiquant si un internaute a cliqué sur une publicité. \r\nNous tenterons de créer un modèle qui prédira si un utilisateur cliquera ou non sur une publicité en fonction de ses caractéristiques.\r\n\r\n#### Description des Données\r\nNotre jeu de données contient les colonnes suivantes:\r\n\r\n- Daily Time Spent on Site: Temps passé par le consommateur sur le site (en minutes)\r\n\r\n- Age: Âge du client (en années)\r\n\r\n- Area Income: Revenu moyen de la zone géographique du consommateur\r\n\r\n- Daily Internet Usage: Nombre moyen de minutes par jour passées sur internet\r\n\r\n- Ad Topic Line: Titre de la publicité\r\n\r\n- City: Ville du consommateur\r\n\r\n- Male: Indique si le consommateur est un homme\r\n\r\n- Country: Pays du consommateur\r\n\r\n- Timestamp: Moment où le consommateur a cliqué sur la publicité ou fermé la fenêtre\r\n\r\n- Clicked on Ad: Variable cible indiquant si l\u0027utilisateur a cliqué sur la publicité (0 ou 1)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 1. Chargement des Données (le fichier \"advertisement.csv\" aura été préalablement déposé sous /user/share/advertisement.csv)\n##### Voir ici ci-besoin : https://github.com/crystalloide/Big_Data/blob/master/advertisement.csv  "
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\r\n// Chargement du fichier CSV\r\nval csv \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/user/share/advertisement.csv\")\r\n\r\n// Affichage des 10 premières lignes\r\ncsv.show(10)\r\n\r\n// Affichage du schéma (structure des données)\r\ncsv.printSchema()\r\n\r\n// Statistiques descriptives sur toutes les colonnes\r\ncsv.describe().show()\r\n\r\n\r\n// Statistiques sur certaines colonnes spécifiques\r\ncsv.select(\"Age\", \"Daily Time Spent on Site\", \"Area Income\", \"Daily Internet Usage\").describe().show(false)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 2. Visualisation des Données"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\r\n// Création d\u0027une vue temporaire pour effectuer des requêtes SQL\r\ncsv.createOrReplaceTempView(\"ads_data\")\r\n\r\n// Requête SQL simple pour vérifier les données\r\nspark.sql(\"SELECT * FROM ads_data LIMIT 10\").show()\r\n\r\n// Visualisation du nombre d\u0027âge différent :\r\nval ageDataDiff \u003d spark.sql(\"SELECT COUNT(DISTINCT Age) AS DistinctAgeCount FROM ads_data\")\r\n\r\nageDataDiff.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nval ageData \u003d spark.sql(\"SELECT Age FROM ads_data\") // Histogramme des âges\n\nageData.show()\nz.show(ageData) // Pour les visualisations avancées\n\n// Graphique de dispersion âge/revenu\nval incomeByAge \u003d spark.sql(\"SELECT `Age`, `Area Income` FROM ads_data\")\nz.show(incomeByAge)\n\n// Graphique âge/temps passé sur le site\nval timeByAge \u003d spark.sql(\"SELECT Age, `Daily Time Spent on Site` FROM ads_data\")\nz.show(timeByAge)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 3. Préparation des Données pour le Machine Learning"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\r\n// Définition des colonnes de type string à convertir\r\nval stringFeatureCols \u003d Array(\"Ad Topic Line\", \"City\", \"Country\")\r\n\r\n// Importation des bibliothèques nécessaires\r\nimport org.apache.spark.ml.feature.StringIndexer\r\nimport org.apache.spark.ml.Pipeline\r\n\r\n// Démonstration du fonctionnement de StringIndexer sur un exemple simple\r\nval df \u003d spark.createDataFrame(Seq(\r\n  (0, \"a\"),\r\n  (1, \"b\"),\r\n  (2, \"c\"),\r\n  (3, \"a\"),\r\n  (4, \"a\"),\r\n  (5, \"c\")\r\n)).toDF(\"id\", \"category\")\r\n\r\nval indexer \u003d new StringIndexer()\r\n  .setInputCol(\"category\")\r\n  .setOutputCol(\"categoryIndex\")\r\n\r\nval indexed \u003d indexer.fit(df).transform(df)\r\n// Remplacer display() par show() pour afficher les résultats dans Zeppelin\r\nindexed.show()\r\n\r\n// Application de StringIndexer à nos colonnes textuelles\r\nimport org.apache.spark.ml.attribute.Attribute\r\nimport org.apache.spark.ml.feature.StringIndexer\r\nimport org.apache.spark.ml.Pipeline\r\nimport org.apache.spark.ml.PipelineModel\r\n\r\nval indexers \u003d stringFeatureCols.map { colName \u003d\u003e\r\n  new StringIndexer()\r\n    .setInputCol(colName)\r\n    .setHandleInvalid(\"skip\")\r\n    .setOutputCol(colName + \"_index\")\r\n}\r\n\r\nval pipeline \u003d new Pipeline().setStages(indexers)\r\nval adsFinalDF \u003d pipeline.fit(csv).transform(csv)\r\n\r\n// Affichage du nouveau schéma incluant les colonnes indexées\r\nadsFinalDF.printSchema()\r\n\r\n// Affichage des données avec les nouvelles colonnes indexées\r\nadsFinalDF.show()\r\n\r\n// Nombre total d\u0027enregistrements\r\nprintln(s\"Nombre total d\u0027enregistrements: ${adsFinalDF.count()}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 4. Division des Données en Ensembles d\u0027Entraînement et de Test\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Division des données: 70% pour l\u0027entraînement, 30% pour le test\nval splits \u003d adsFinalDF.randomSplit(Array(0.7, 0.3))\nval train \u003d splits(0)\nval test \u003d splits(1)\n\n// Affichage du nombre d\u0027enregistrements dans chaque ensemble\nprintln(s\"Ensemble d\u0027entraînement: ${train.count()} enregistrements\")\nprintln(s\"Ensemble de test: ${test.count()} enregistrements\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 5. Création du Modèle de Régression Logistique\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Importation des bibliothèques\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.classification.LogisticRegression\n\n// Préparation des données avec VectorAssembler pour regrouper toutes les features dans une seule colonne\nval assembler \u003d new VectorAssembler()\n  .setInputCols(Array(\"Daily Time Spent on Site\", \"Age\", \"Area Income\", \"Daily Internet Usage\", \n                     \"Ad Topic Line_index\", \"City_index\", \"Male\", \"Country_index\"))\n  .setOutputCol(\"features\")\n\n// Transformation de l\u0027ensemble d\u0027entraînement\nval training \u003d assembler.transform(train)\n  .select($\"features\", $\"Clicked on Ad\".as(\"label\"))\n\n// Affichage des données préparées\ntraining.show(false)\n\n// Création du modèle de régression logistique\nval lr \u003d new LogisticRegression()\n  .setLabelCol(\"label\")\n  .setFeaturesCol(\"features\")\n  .setMaxIter(10)\n  .setRegParam(0.3)\n\n// Entraînement du modèle\nval model \u003d lr.fit(training)\n\n// Transformation de l\u0027ensemble de test\nval testing \u003d assembler.transform(test)\n  .select($\"features\", $\"Clicked on Ad\".as(\"trueLabel\"))\n\n// Prédiction sur l\u0027ensemble de test\nval prediction \u003d model.transform(testing)\n  .select($\"features\", $\"prediction\", $\"trueLabel\")\n\n// Affichage des prédictions\nprediction.show(10)\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 6. Évaluation du Modèle"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Importation des bibliothèques nécessaires pour l\u0027évaluation\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n\n// Création de l\u0027évaluateur\nval evaluator \u003d new MulticlassClassificationEvaluator()\n  .setLabelCol(\"trueLabel\")\n  .setPredictionCol(\"prediction\")\n  .setMetricName(\"accuracy\")\n\n// Calcul de l\u0027exactitude (accuracy)\nval accuracy \u003d evaluator.evaluate(prediction)\nprintln(s\"Exactitude du modèle: ${accuracy * 100}%\")\n\n// Calcul de la matrice de confusion\nval tp \u003d prediction.filter($\"prediction\" \u003d\u003d\u003d 1.0 \u0026\u0026 $\"trueLabel\" \u003d\u003d\u003d 1.0).count() // Vrais positifs\nval fp \u003d prediction.filter($\"prediction\" \u003d\u003d\u003d 1.0 \u0026\u0026 $\"trueLabel\" \u003d\u003d\u003d 0.0).count() // Faux positifs\nval tn \u003d prediction.filter($\"prediction\" \u003d\u003d\u003d 0.0 \u0026\u0026 $\"trueLabel\" \u003d\u003d\u003d 0.0).count() // Vrais négatifs\nval fn \u003d prediction.filter($\"prediction\" \u003d\u003d\u003d 0.0 \u0026\u0026 $\"trueLabel\" \u003d\u003d\u003d 1.0).count() // Faux négatifs\n\nprintln(\"Matrice de confusion:\")\nprintln(s\"Vrais positifs (TP): $tp\")\nprintln(s\"Faux positifs (FP): $fp\")\nprintln(s\"Vrais négatifs (TN): $tn\")\nprintln(s\"Faux négatifs (FN): $fn\")\n\n// Calcul de la précision et du rappel\nval precision \u003d tp.toDouble / (tp + fp)\nval recall \u003d tp.toDouble / (tp + fn)\nval f1Score \u003d 2 * precision * recall / (precision + recall)\n\nprintln(s\"Précision: ${precision * 100}%\")\nprintln(s\"Rappel: ${recall * 100}%\")\nprintln(s\"Score F1: ${f1Score * 100}%\")\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Conclusion\n\n### Dans ce notebook, nous avons développé un modèle de régression logistique pour prédire si un utilisateur cliquera sur une publicité en fonction de ses caractéristiques. \n\n#### Notre modèle a atteint une précision \u003e 90%, ce qui est excellent pour ce type de problème.\n\n#### Cette analyse peut aider les entreprises à optimiser leurs campagnes publicitaires en ciblant les utilisateurs les plus susceptibles de cliquer sur leurs annonces, \naméliorant ainsi le retour sur investissement de leurs efforts marketing.\n\n#### Pour améliorer davantage ce modèle, nous pourrions:\n\n- Explorer d\u0027autres algorithmes de classification\n\n- Effectuer une sélection de caractéristiques plus approfondie\n\n- Ajuster les hyperparamètres du modèle\n\n- Collecter plus de données pour l\u0027entraînement\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    }
  ]
}