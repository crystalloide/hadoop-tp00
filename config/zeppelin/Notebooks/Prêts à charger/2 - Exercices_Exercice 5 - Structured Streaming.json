{"paragraphs":[{"text":"%md\n\n### Bienvenue dans ce cinquième exercice\n\nDans cet exercice, nous allons voir comment utiliser l'api Spark SQL pour créer une application en streaming.\nNous allons créer des compteurs à partir de données provenant du site d'annonces en ligne LeBonCoin.\n\n#### Documentation du Structured Streaming : [Structured Streaming Programming Guide](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Bienvenue dans ce cinquième exercice</h3>\n<p>Dans cet exercice, nous allons voir comment utiliser l&rsquo;api Spark SQL pour créer une application en streaming.<br/>Nous allons créer des compteurs à partir de données provenant du site d&rsquo;annonces en ligne LeBonCoin.</p>\n<h4>Documentation du Structured Streaming : <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\">Structured Streaming Programming Guide</a></h4>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497395_-1613177119","id":"20180224-142716_1461800465","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:43666"},{"text":"%sh\n\n# Nous allons en fait simuler une ingestion de données en temps réel.\n# Le dossier /data/data/lbc_json contient 205 dossiers organisés par ordre chronologique que nous allons ingérés à la vitesse de 1 par seconde.\n\nls /data/data/lbc_json","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"date=2015-03-07\ndate=2015-06-03\ndate=2015-07-28\ndate=2015-09-04\ndate=2015-09-05\ndate=2015-10-14\ndate=2015-10-30\ndate=2015-12-16\ndate=2015-12-28\ndate=2016-01-02\ndate=2016-01-04\ndate=2016-01-12\ndate=2016-02-01\ndate=2016-02-23\ndate=2016-03-04\ndate=2016-03-07\ndate=2016-03-16\ndate=2016-03-21\ndate=2016-03-29\ndate=2016-04-26\ndate=2016-04-30\ndate=2016-05-04\ndate=2016-05-12\ndate=2016-05-13\ndate=2016-05-23\ndate=2016-05-26\ndate=2016-05-27\ndate=2016-05-31\ndate=2016-06-01\ndate=2016-06-02\ndate=2016-06-08\ndate=2016-06-12\ndate=2016-06-18\ndate=2016-06-22\ndate=2016-06-25\ndate=2016-06-27\ndate=2016-06-30\ndate=2016-07-02\ndate=2016-07-04\ndate=2016-07-05\ndate=2016-07-06\ndate=2016-07-07\ndate=2016-07-12\ndate=2016-07-14\ndate=2016-07-16\ndate=2016-07-18\ndate=2016-07-19\ndate=2016-07-22\ndate=2016-07-23\ndate=2016-07-25\ndate=2016-07-26\ndate=2016-07-27\ndate=2016-07-28\ndate=2016-07-29\ndate=2016-08-02\ndate=2016-08-03\ndate=2016-08-04\ndate=2016-08-05\ndate=2016-08-08\ndate=2016-08-09\ndate=2016-08-10\ndate=2016-08-11\ndate=2016-08-12\ndate=2016-08-13\ndate=2016-08-16\ndate=2016-08-17\ndate=2016-08-18\ndate=2016-08-19\ndate=2016-08-22\ndate=2016-08-24\ndate=2016-08-26\ndate=2016-08-29\ndate=2016-08-30\ndate=2016-08-31\ndate=2016-09-04\ndate=2016-09-05\ndate=2016-09-06\ndate=2016-09-07\ndate=2016-09-08\ndate=2016-09-09\ndate=2016-09-10\ndate=2016-09-12\ndate=2016-09-13\ndate=2016-09-14\ndate=2016-09-15\ndate=2016-09-16\ndate=2016-09-17\ndate=2016-09-18\ndate=2016-09-19\ndate=2016-09-20\ndate=2016-09-21\ndate=2016-09-22\ndate=2016-09-23\ndate=2016-09-24\ndate=2016-09-26\ndate=2016-09-27\ndate=2016-09-29\ndate=2016-09-30\ndate=2016-10-01\ndate=2016-10-03\ndate=2016-10-04\ndate=2016-10-05\ndate=2016-10-06\ndate=2016-10-07\ndate=2016-10-08\ndate=2016-10-10\ndate=2016-10-11\ndate=2016-10-12\ndate=2016-10-13\ndate=2016-10-14\ndate=2016-10-15\ndate=2016-10-18\ndate=2016-10-19\ndate=2016-10-20\ndate=2016-10-21\ndate=2016-10-24\ndate=2016-10-25\ndate=2016-10-26\ndate=2016-10-27\ndate=2016-10-28\ndate=2016-10-29\ndate=2016-10-31\ndate=2016-11-02\ndate=2016-11-03\ndate=2016-11-04\ndate=2016-11-05\ndate=2016-11-07\ndate=2016-11-08\ndate=2016-11-09\ndate=2016-11-10\ndate=2016-11-11\ndate=2016-11-12\ndate=2016-11-14\ndate=2016-11-15\ndate=2016-11-16\ndate=2016-11-17\ndate=2016-11-18\ndate=2016-11-19\ndate=2016-11-21\ndate=2016-11-22\ndate=2016-11-23\ndate=2016-11-24\ndate=2016-11-25\ndate=2016-11-27\ndate=2016-11-28\ndate=2016-11-29\ndate=2016-11-30\ndate=2016-12-01\ndate=2016-12-02\ndate=2016-12-03\ndate=2016-12-04\ndate=2016-12-05\ndate=2016-12-06\ndate=2016-12-07\ndate=2016-12-08\ndate=2016-12-09\ndate=2016-12-10\ndate=2016-12-12\ndate=2016-12-13\ndate=2016-12-14\ndate=2016-12-15\ndate=2016-12-16\ndate=2016-12-17\ndate=2016-12-19\ndate=2016-12-20\ndate=2016-12-21\ndate=2016-12-22\ndate=2016-12-23\ndate=2016-12-24\ndate=2016-12-26\ndate=2016-12-27\ndate=2016-12-28\ndate=2016-12-29\ndate=2016-12-30\ndate=2016-12-31\ndate=2017-01-02\ndate=2017-01-03\ndate=2017-01-04\ndate=2017-01-05\ndate=2017-01-06\ndate=2017-01-07\ndate=2017-01-08\ndate=2017-01-09\ndate=2017-01-10\ndate=2017-01-11\ndate=2017-01-12\ndate=2017-01-13\ndate=2017-01-14\ndate=2017-01-15\ndate=2017-01-16\ndate=2017-01-17\ndate=2017-01-18\ndate=2017-01-19\ndate=2017-01-20\ndate=2017-01-21\ndate=2017-01-22\ndate=2017-01-23\ndate=2017-01-24\ndate=2017-01-25\ndate=2017-01-26\ndate=2017-01-27\ndate=2017-01-28\ndate=2017-01-29\ndate=2017-01-30\ndate=2017-01-31\n"}]},"apps":[],"jobName":"paragraph_1601895497396_-1615100863","id":"20180224-143805_693437951","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43667"},{"text":"%md\n\n### Aperçu des données étudiés","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Aperçu des données étudiés</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497396_-1615100863","id":"20180224-161140_924868858","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43668"},{"text":"%spark\n\n// Q1 - Pour vous familiariser avec les données, affichez les premières lignes du fichier json situé dans le dossier \"/data/data/lbc_json/date=2015-03-07/\". Il ne devrait y avoir qu'une ligne dans ce dossier.\nspark.read.json(\"/data/data/lbc_json/date=2015-03-07/*\").show(5, 16)\n","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+----------------+-----+-----------+----------------+-----+-------+------+-------+---------------+------+----------------+----+-------------+----------------+----------------+\n|annee|            city|   cp|departement|            desc|   km| marque|modele|    nrj|oas_departement|offres|    pretty_title|prix|       region|          seller|           titre|\n+-----+----------------+-----+-----------+----------------+-----+-------+------+-------+---------------+------+----------------+----+-------------+----------------+----------------+\n| 2013|noidans_les_v...|70000|haute_saone|Peugeot 208 1...|16347|peugeot|   208|essence|             70|   pro|Peugeot 208 1...|8690|franche_comte|SIVA PEUGEOT ...|peugeot_208_1...|\n+-----+----------------+-----+-----------+----------------+-----+-------+------+-------+---------------+------+----------------+----+-------------+----------------+----------------+\n\n"}]},"apps":[],"jobName":"paragraph_1601895497396_-1615100863","id":"20180224-161320_1484425195","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43669"},{"text":"%md\n\n### Import des librairies nécessaires\n","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Import des librairies nécessaires</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497396_-1615100863","id":"20180224-144422_4869310","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43670"},{"text":"%spark\n\nimport spark.implicits._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.streaming.Trigger\nimport java.util.concurrent.TimeUnit","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.streaming.Trigger\nimport java.util.concurrent.TimeUnit\n"}]},"apps":[],"jobName":"paragraph_1601895497397_-1615485612","id":"20180224-143425_1314840125","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43671"},{"text":"%md\n\n### Définiation du schéma de donnée.","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Définiation du schéma de donnée.</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497397_-1615485612","id":"20180224-144527_1937755177","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43672"},{"text":"%spark\n\n// Pour traîter des données en streaming, spark a besoin de connaitre le schéma des données.\n\nval mySchema = StructType(Seq(StructField(\"annee\",StringType,true), StructField(\"city\",StringType,true), StructField(\"cp\",StringType,true), StructField(\"departement\",StringType,true), StructField(\"desc\",StringType,true), StructField(\"km\",StringType,true), StructField(\"marque\",StringType,true), StructField(\"modele\",StringType,true), StructField(\"nrj\",StringType,true), StructField(\"oas_departement\",StringType,true), StructField(\"offres\",StringType,true), StructField(\"pretty_title\",StringType,true), StructField(\"prix\",StringType,true), StructField(\"date\",TimestampType,true), StructField(\"region\",StringType,true), StructField(\"seller\",StringType,true), StructField(\"titre\",StringType,true)))","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"mySchema: org.apache.spark.sql.types.StructType = StructType(StructField(annee,StringType,true), StructField(city,StringType,true), StructField(cp,StringType,true), StructField(departement,StringType,true), StructField(desc,StringType,true), StructField(km,StringType,true), StructField(marque,StringType,true), StructField(modele,StringType,true), StructField(nrj,StringType,true), StructField(oas_departement,StringType,true), StructField(offres,StringType,true), StructField(pretty_title,StringType,true), StructField(prix,StringType,true), StructField(date,TimestampType,true), StructField(region,StringType,true), StructField(seller,StringType,true), StructField(titre,StringType,true))\n"}]},"apps":[],"jobName":"paragraph_1601895497397_-1615485612","id":"20180224-142315_1038233516","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43673"},{"text":"%md\n\n# Partie 1","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Partie 1</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497397_-1615485612","id":"20180227-180521_1625930874","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43674"},{"text":"%md\n\n## Création du Dataframe d'input\n\nVous allez maintenant créer un dataframe sur les données au format json.\n\nDans le cas d'un traitement batch, la création du dataframe static peut se faire de la manière suivante :\n```\nval staticInputDF = \n    spark\n        .read\n        .schema(mySchema)\n        .option(\"key\", value)\n        .json(inputPath)\n```\n\nPour créer un dataframe sur des données non statiques, la syntaxe est très proche :\n```\nval streamingInputDF = \n    spark\n        .readStream\n        .schema(mySchema)\n        .option(\"key\", value)\n        .json(inputPath)\n```","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Création du Dataframe d&rsquo;input</h2>\n<p>Vous allez maintenant créer un dataframe sur les données au format json.</p>\n<p>Dans le cas d&rsquo;un traitement batch, la création du dataframe static peut se faire de la manière suivante :</p>\n<pre><code>val staticInputDF = \n    spark\n        .read\n        .schema(mySchema)\n        .option(&quot;key&quot;, value)\n        .json(inputPath)\n</code></pre>\n<p>Pour créer un dataframe sur des données non statiques, la syntaxe est très proche :</p>\n<pre><code>val streamingInputDF = \n    spark\n        .readStream\n        .schema(mySchema)\n        .option(&quot;key&quot;, value)\n        .json(inputPath)\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497397_-1615485612","id":"20180224-144521_1989688648","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43675"},{"text":"%spark\nspark.conf.set(\"spark.sql.shuffle.partitions\", \"2\") // Pour de meilleures performance de shuffle nous gardons uniquement 2 partitions.\nval inputPath = \"/data/data/lbc_json\"\n\n\n// Q2 - Créez un dataframe streaming avec comme option \"maxFilesPerTrigger\" configuré à 1.\n// Cela va nous permettre de simuler un processus de streaming.\n\nval streamingInputDF = \n  spark\n    .readStream\n    .schema(mySchema)\n    .option(\"maxFilesPerTrigger\", 1)\n    .json(inputPath)","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"inputPath: String = /data/data/lbc_json\nstreamingInputDF: org.apache.spark.sql.DataFrame = [annee: string, city: string ... 15 more fields]\n"}]},"apps":[],"jobName":"paragraph_1601895497398_-1614331366","id":"20180224-144721_1824688773","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43676"},{"text":"%spark\n\n// Q3 - Controllez que le dataframe créé est bien capturé en streaming grâce à la fonction dataset.isStreaming\n\nstreamingInputDF.isStreaming","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res79: Boolean = true\n"}]},"apps":[],"jobName":"paragraph_1601895497398_-1614331366","id":"20180224-153956_416700776","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43677"},{"text":"%md\n\nNous avons définis notre source mais nous n'avons pas démarré le streaming. Pour cela il faut définir une destination mais nous allons dans un premier temps effectuer quelques transformations.\n\n### Première transformation\nAvant cela, comme défini dans notre schéma, la colonne année est un String.","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Nous avons définis notre source mais nous n&rsquo;avons pas démarré le streaming. Pour cela il faut définir une destination mais nous allons dans un premier temps effectuer quelques transformations.</p>\n<h3>Première transformation</h3>\n<p>Avant cela, comme défini dans notre schéma, la colonne année est un String.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497398_-1614331366","id":"20180224-154340_1377545025","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43678"},{"text":"%spark\n\n// Q4 - Castez la colonne \"annee\" en Integer.\nval df1 = streamingInputDF.withColumn(\"annee\", $\"annee\".cast(\"integer\"))\nval df1_bis = streamingInputDF.withColumn(\"annee\", col(\"annee\").cast(\"int\"))\nval df1_bisbis = streamingInputDF.withColumn(\"annee\", col(\"annee\").cast(IntegerType))\n\ndf1.schema // Le champs année doit maintenant être de type IntegerType","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df1: org.apache.spark.sql.DataFrame = [annee: int, city: string ... 15 more fields]\ndf1_bis: org.apache.spark.sql.DataFrame = [annee: int, city: string ... 15 more fields]\ndf1_bisbis: org.apache.spark.sql.DataFrame = [annee: int, city: string ... 15 more fields]\nres82: org.apache.spark.sql.types.StructType = StructType(StructField(annee,IntegerType,true), StructField(city,StringType,true), StructField(cp,StringType,true), StructField(departement,StringType,true), StructField(desc,StringType,true), StructField(km,StringType,true), StructField(marque,StringType,true), StructField(modele,StringType,true), StructField(nrj,StringType,true), StructField(oas_departement,StringType,true), StructField(offres,StringType,true), StructField(pretty_title,StringType,true), StructField(prix,StringType,true), StructField(region,StringType,true), StructField(seller,StringType,true), StructField(titre,StringType,true), StructField(date,TimestampType,true))\n"}]},"apps":[],"jobName":"paragraph_1601895497398_-1614331366","id":"20180224-154422_777123909","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43679"},{"text":"%md\n\n### Seconde transformation\n\nL'api de spark nous permet d'aggreger des donnes temporelles.\nEn vous aidant de la documentation, créez un nouveau dataframe qui, pour chaque window de 10 jours, compte le nombre d'annonce posté pour chaque marque.\n\n#### Documentation : [Window Operations on Event Time](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#window-operations-on-event-time)","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Seconde transformation</h3>\n<p>L&rsquo;api de spark nous permet d&rsquo;aggreger des donnes temporelles.<br/>En vous aidant de la documentation, créez un nouveau dataframe qui, pour chaque window de 10 jours, compte le nombre d&rsquo;annonce posté pour chaque marque.</p>\n<h4>Documentation : <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#window-operations-on-event-time\">Window Operations on Event Time</a></h4>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497398_-1614331366","id":"20180224-160716_396493521","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43680"},{"text":"%spark\n\n// Q5 - Aide : Les deux colones à utiliser sont \"marque\" et \"date\". La \"date\" correspondant à la date de soumission de l'annonce.\nval df2 =               \n  df1\n    .groupBy(\n      col(\"marque\"), \n      window(col(\"date\"), \"10 day\"))\n    .count()\n    \ndf2.schema\n// Vous devez obtenir un schéma sous la forme :\n// marque, window:(start,end), count","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df2: org.apache.spark.sql.DataFrame = [marque: string, window: struct<start: timestamp, end: timestamp> ... 1 more field]\nres85: org.apache.spark.sql.types.StructType = StructType(StructField(marque,StringType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true), StructField(count,LongType,false))\n"}]},"apps":[],"jobName":"paragraph_1601895497399_-1614716115","id":"20180224-161646_1537608974","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43681"},{"text":"%md\n\n## Lancement du streaming\n\nDans le cas de l'api SQL batch, pour executer l'ensemble de vos actions et sauvegarder votre résultat la méthode est par exemple :\n```\nspark\n    .write\n    .format(\"json\")\n    .save()\n```\n\nDans le cas du streaming la syntaxe reste proche.\nPar exemple si nous souhaitons écrire notre résultat dans un table en mémoire nommé \"counts\" :\n```\nval query = \n  df2\n    .writeStream\n    .format(\"memory\")        // memory = à des fins de tests crée une table en mémoire\n    .queryName(\"counts\")     // counts = nom de la table en mémoire\n    .outputMode(\"complete\")  // complete = toutes les lignes seront dans la table\n    .trigger(Trigger.ProcessingTime(2, TimeUnit.SECONDS)) // Délais entre deux itérations\n    .start()\n```","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Lancement du streaming</h2>\n<p>Dans le cas de l&rsquo;api SQL batch, pour executer l&rsquo;ensemble de vos actions et sauvegarder votre résultat la méthode est par exemple :</p>\n<pre><code>spark\n    .write\n    .format(&quot;json&quot;)\n    .save()\n</code></pre>\n<p>Dans le cas du streaming la syntaxe reste proche.<br/>Par exemple si nous souhaitons écrire notre résultat dans un table en mémoire nommé &ldquo;counts&rdquo; :</p>\n<pre><code>val query = \n  df2\n    .writeStream\n    .format(&quot;memory&quot;)        // memory = à des fins de tests crée une table en mémoire\n    .queryName(&quot;counts&quot;)     // counts = nom de la table en mémoire\n    .outputMode(&quot;complete&quot;)  // complete = toutes les lignes seront dans la table\n    .trigger(Trigger.ProcessingTime(2, TimeUnit.SECONDS)) // Délais entre deux itérations\n    .start()\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497399_-1614716115","id":"20180224-155737_1274422113","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43682"},{"text":"%md\n\nL'une des principales différence est que la fonction `writeStream` retourne un objet de type StreamingQuery. C'est cet objet qui va nous permettre de contrôler l'execution de notre streaming.\n\nJe vous invite à jetter un oeil sur cette partie de la documentation décrivant les possibilités de l'objet StreamingQuery :\n#### [Managing Streaming Queries](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#managing-streaming-queries)","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>L&rsquo;une des principales différence est que la fonction <code>writeStream</code> retourne un objet de type StreamingQuery. C&rsquo;est cet objet qui va nous permettre de contrôler l&rsquo;execution de notre streaming.</p>\n<p>Je vous invite à jetter un oeil sur cette partie de la documentation décrivant les possibilités de l&rsquo;objet StreamingQuery :</p>\n<h4><a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#managing-streaming-queries\">Managing Streaming Queries</a></h4>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497399_-1614716115","id":"20180227-172935_567297262","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43683"},{"text":"%spark\n\n// Q6 - Vous pouvez maintenant démarrer votre streaming sur votre dataframe contenant votre aggregation sur 10 jours et stocker le résultat dans une table en mémoire.\n\nval query = \n  df2\n    .writeStream\n    .format(\"memory\")        // memory = à des fins de tests crée une table en mémoire\n    .queryName(\"counts\")     // counts = nom de la table en mémoire\n    .outputMode(\"complete\")  // complete = toutes les lignes seront dans la table\n    .trigger(Trigger.ProcessingTime(2, TimeUnit.SECONDS)) // Délais entre deux itérations\n    .start()","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.IllegalArgumentException: Cannot start query with name counts as a query with that name is already active\n  at org.apache.spark.sql.streaming.StreamingQueryManager$$anonfun$startQuery$1.apply(StreamingQueryManager.scala:293)\n  at org.apache.spark.sql.streaming.StreamingQueryManager$$anonfun$startQuery$1.apply(StreamingQueryManager.scala:291)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.sql.streaming.StreamingQueryManager.startQuery(StreamingQueryManager.scala:291)\n  at org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:247)\n  ... 54 elided\n"}]},"apps":[],"jobName":"paragraph_1601895497399_-1614716115","id":"20180224-155552_458421615","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43684"},{"text":"%md\n\n## Un peu de SQL pour visualiser le résultat\n\nIl ne vous reste plus qu'à visualiser votre table en SQL.\n\nToutes les 2 secondes un nouveau fichier sera ingéré dans le dataframe.","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Un peu de SQL pour visualiser le résultat</h2>\n<p>Il ne vous reste plus qu&rsquo;à visualiser votre table en SQL.</p>\n<p>Toutes les 2 secondes un nouveau fichier sera ingéré dans le dataframe.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497400_-1616639859","id":"20180224-162959_946851188","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43685"},{"text":"%sql\n\n-- Q7 - Comptez combien vous avez de lignes dans votre table. Executez la requête plusieurs pour observer l'ajouts de nouvelles données.\n\nselect count(*) from counts\n","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"count(1)\n345\n"}]},"apps":[],"jobName":"paragraph_1601895497400_-1616639859","id":"20180224-163741_1892791001","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43686"},{"text":"%sql\n\n-- Q8 affichez la dernière window enregistré dans la table.\n\nselect max(window) from counts\n","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"window","index":1,"aggr":"sum"}],"groups":[],"values":[]},"helium":{}}},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"max(window)\n[2017-01-24 00:00:00.0,2017-02-03 00:00:00.0]\n"}]},"apps":[],"jobName":"paragraph_1601895497400_-1616639859","id":"20180224-162939_1472714388","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43687"},{"text":"%md\n\n### Mise en forme des données\n\nConstruisez un graphique à barres affichant pour chaque période de 10 jours le cumul des annonces par marque (il n'y a pas forcément des données sur chaque période de 10 jours)\n\nAstuce : pour la mise en forme, transformez le champs window en utilisant la fonction `date_format(window.end, \"yyyy-MM-dd\") as time`\n","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Mise en forme des données</h3>\n<p>Construisez un graphique à barres affichant pour chaque période de 10 jours le cumul des annonces par marque (il n&rsquo;y a pas forcément des données sur chaque période de 10 jours)</p>\n<p>Astuce : pour la mise en forme, transformez le champs window en utilisant la fonction <code>date_format(window.end, &quot;yyyy-MM-dd&quot;) as time</code></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497400_-1616639859","id":"20180224-163227_549082444","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43688"},{"text":"%sql\n\nselect marque, date_format(window.end, \"yyyy-MM-dd\") as time, count from counts order by time","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":true}},"commonSetting":{},"keys":[{"name":"time","index":1,"aggr":"sum"}],"groups":[{"name":"marque","index":0,"aggr":"sum"}],"values":[{"name":"count","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"marque\ttime\tcount\npeugeot\t2015-03-16\t1\ncitroen\t2015-06-04\t1\nvolkswagen\t2015-08-03\t1\naudi\t2015-09-12\t1\npeugeot\t2015-09-12\t1\nvolkswagen\t2015-10-22\t1\nfiat\t2015-10-22\t1\nmercedes\t2015-11-01\t1\nopel\t2015-12-21\t1\nmercedes\t2015-12-31\t1\nbmw\t2016-01-10\t1\nskoda\t2016-01-10\t1\nnissan\t2016-01-20\t1\naudi\t2016-02-09\t1\nnissan\t2016-02-29\t1\nmercedes\t2016-03-10\t1\npeugeot\t2016-03-10\t1\nopel\t2016-03-20\t1\npeugeot\t2016-03-30\t1\naudi\t2016-03-30\t1\nmini\t2016-03-30\t1\nopel\t2016-04-29\t1\nbmw\t2016-05-09\t1\nrenault\t2016-05-09\t1\nrenault\t2016-05-19\t2\ncitroen\t2016-05-19\t1\nrenault\t2016-05-29\t1\nhyundai\t2016-05-29\t1\npeugeot\t2016-05-29\t1\nrenault\t2016-06-08\t2\ncitroen\t2016-06-08\t1\npeugeot\t2016-06-18\t1\nnissan\t2016-06-18\t1\ncitroen\t2016-06-18\t1\nrenault\t2016-06-28\t2\ncitroen\t2016-06-28\t1\nopel\t2016-06-28\t1\ncitroen\t2016-07-08\t1\nvolkswagen\t2016-07-08\t1\nrenault\t2016-07-08\t2\nford\t2016-07-08\t1\nsubaru\t2016-07-08\t1\nbmw\t2016-07-08\t2\nopel\t2016-07-08\t1\nopel\t2016-07-18\t1\nfiat\t2016-07-18\t1\naudi\t2016-07-18\t1\nrenault\t2016-07-18\t1\nrenault\t2016-07-28\t2\npeugeot\t2016-07-28\t1\nmercedes\t2016-07-28\t3\nopel\t2016-07-28\t1\ncitroen\t2016-07-28\t2\nhonda\t2016-07-28\t1\nfiat\t2016-07-28\t1\nvolkswagen\t2016-07-28\t1\ncitroen\t2016-08-07\t3\nds\t2016-08-07\t2\nbmw\t2016-08-07\t1\nfiat\t2016-08-07\t1\npeugeot\t2016-08-07\t2\nvolkswagen\t2016-08-07\t1\nkia\t2016-08-07\t1\nrenault\t2016-08-07\t1\nlancia\t2016-08-17\t1\nfiat\t2016-08-17\t1\naudi\t2016-08-17\t1\ntoyota\t2016-08-17\t3\nnissan\t2016-08-17\t2\ncitroen\t2016-08-17\t2\nporsche\t2016-08-17\t1\nalfa_romeo\t2016-08-17\t1\nopel\t2016-08-17\t2\nchevrolet\t2016-08-17\t1\nrenault\t2016-08-17\t4\npeugeot\t2016-08-17\t2\nmercedes\t2016-08-27\t1\nrenault\t2016-08-27\t6\nford\t2016-08-27\t1\nmini\t2016-08-27\t1\ncitroen\t2016-08-27\t2\ndacia\t2016-09-06\t1\nporsche\t2016-09-06\t2\nmercedes\t2016-09-06\t1\npeugeot\t2016-09-06\t4\nrenault\t2016-09-06\t3\nfiat\t2016-09-16\t1\ncitroen\t2016-09-16\t1\npeugeot\t2016-09-16\t2\nbmw\t2016-09-16\t2\nrenault\t2016-09-16\t7\nford\t2016-09-16\t1\nmitsubishi\t2016-09-16\t1\nvolvo\t2016-09-26\t1\naudi\t2016-09-26\t1\nhyundai\t2016-09-26\t1\nmg\t2016-09-26\t1\nmercedes\t2016-09-26\t1\nnissan\t2016-09-26\t1\nrenault\t2016-09-26\t7\nds\t2016-09-26\t1\nsuzuki\t2016-09-26\t1\nopel\t2016-09-26\t1\ncitroen\t2016-09-26\t2\npeugeot\t2016-09-26\t2\nvolkswagen\t2016-09-26\t1\nbmw\t2016-09-26\t1\nford\t2016-10-06\t1\ncitroen\t2016-10-06\t2\nvolkswagen\t2016-10-06\t1\nmini\t2016-10-06\t1\nfiat\t2016-10-06\t1\nopel\t2016-10-06\t3\nbmw\t2016-10-06\t2\npeugeot\t2016-10-06\t4\naudi\t2016-10-06\t2\nrenault\t2016-10-06\t2\npeugeot\t2016-10-16\t9\ncitroen\t2016-10-16\t3\nmaserati\t2016-10-16\t2\nvolkswagen\t2016-10-16\t3\nds\t2016-10-16\t2\nfiat\t2016-10-16\t2\nopel\t2016-10-16\t5\nrenault\t2016-10-16\t5\nbentley\t2016-10-16\t1\nford\t2016-10-16\t3\nsubaru\t2016-10-16\t1\nopel\t2016-10-26\t1\naudi\t2016-10-26\t1\nbmw\t2016-10-26\t1\ncitroen\t2016-10-26\t4\njeep\t2016-10-26\t1\nnissan\t2016-10-26\t1\nrenault\t2016-10-26\t6\npeugeot\t2016-10-26\t2\nmini\t2016-11-05\t2\nsubaru\t2016-11-05\t1\nvolkswagen\t2016-11-05\t2\npeugeot\t2016-11-05\t7\nfiat\t2016-11-05\t1\ndacia\t2016-11-05\t2\ncitroen\t2016-11-05\t2\nbmw\t2016-11-05\t4\naudi\t2016-11-05\t2\nrenault\t2016-11-05\t13\ntoyota\t2016-11-15\t1\nrenault\t2016-11-15\t4\nfiat\t2016-11-15\t1\naudi\t2016-11-15\t1\nchevrolet\t2016-11-15\t1\nvolkswagen\t2016-11-15\t2\nopel\t2016-11-15\t1\ncitroen\t2016-11-15\t1\npeugeot\t2016-11-15\t6\nrenault\t2016-11-25\t6\nnissan\t2016-11-25\t1\nford\t2016-11-25\t1\nbmw\t2016-11-25\t1\nopel\t2016-11-25\t4\ncitroen\t2016-11-25\t4\nseat\t2016-11-25\t1\nvolkswagen\t2016-11-25\t1\nporsche\t2016-11-25\t1\nds\t2016-11-25\t1\nmercedes\t2016-11-25\t2\npeugeot\t2016-11-25\t5\nvolkswagen\t2016-12-05\t1\ndacia\t2016-12-05\t2\nfiat\t2016-12-05\t3\nmazda\t2016-12-05\t1\nkia\t2016-12-05\t1\nford\t2016-12-05\t2\ncitroen\t2016-12-05\t2\nrenault\t2016-12-05\t8\nbmw\t2016-12-05\t2\naudi\t2016-12-05\t5\nporsche\t2016-12-05\t1\nmercedes\t2016-12-05\t1\nnissan\t2016-12-05\t1\ntoyota\t2016-12-05\t2\nds\t2016-12-05\t1\nseat\t2016-12-05\t1\npeugeot\t2016-12-05\t6\nopel\t2016-12-05\t2\nmini\t2016-12-05\t1\nmini\t2016-12-15\t2\nskoda\t2016-12-15\t1\nbmw\t2016-12-15\t2\nkia\t2016-12-15\t1\nds\t2016-12-15\t1\nford\t2016-12-15\t1\nrenault\t2016-12-15\t16\nmercedes\t2016-12-15\t4\nhyundai\t2016-12-15\t2\nnissan\t2016-12-15\t1\npeugeot\t2016-12-15\t9\nopel\t2016-12-15\t2\nvolkswagen\t2016-12-15\t6\nvolvo\t2016-12-15\t4\naudi\t2016-12-15\t8\ncitroen\t2016-12-15\t6\ntoyota\t2016-12-25\t1\nfiat\t2016-12-25\t1\nbmw\t2016-12-25\t3\nrenault\t2016-12-25\t13\nmercedes\t2016-12-25\t2\njaguar\t2016-12-25\t2\nseat\t2016-12-25\t1\nhyundai\t2016-12-25\t1\npeugeot\t2016-12-25\t6\nvolvo\t2016-12-25\t1\nmini\t2016-12-25\t4\ncitroen\t2016-12-25\t5\nporsche\t2016-12-25\t1\nnissan\t2016-12-25\t1\njeep\t2016-12-25\t1\nvolkswagen\t2016-12-25\t2\naudi\t2016-12-25\t5\nford\t2016-12-25\t6\ncitroen\t2017-01-04\t3\njeep\t2017-01-04\t1\nporsche\t2017-01-04\t1\naudi\t2017-01-04\t2\nford\t2017-01-04\t1\nvolvo\t2017-01-04\t3\nvolkswagen\t2017-01-04\t5\nopel\t2017-01-04\t3\nfiat\t2017-01-04\t4\nskoda\t2017-01-04\t1\nseat\t2017-01-04\t1\nrenault\t2017-01-04\t17\nnissan\t2017-01-04\t3\npeugeot\t2017-01-04\t9\nlancia\t2017-01-04\t1\nland_rover\t2017-01-04\t1\nbmw\t2017-01-04\t1\nhonda\t2017-01-04\t1\nalfa_romeo\t2017-01-04\t1\nautres\t2017-01-14\t1\ninfiniti\t2017-01-14\t1\nporsche\t2017-01-14\t3\nkia\t2017-01-14\t1\njeep\t2017-01-14\t2\nskoda\t2017-01-14\t1\nnissan\t2017-01-14\t5\nbmw\t2017-01-14\t1\naudi\t2017-01-14\t5\npeugeot\t2017-01-14\t15\ncitroen\t2017-01-14\t7\nvolvo\t2017-01-14\t6\nsmart\t2017-01-14\t1\nrenault\t2017-01-14\t25\ndacia\t2017-01-14\t4\nopel\t2017-01-14\t10\nhyundai\t2017-01-14\t1\nfiat\t2017-01-14\t5\nalfa_romeo\t2017-01-14\t1\nmercedes\t2017-01-14\t12\nseat\t2017-01-14\t3\ntoyota\t2017-01-14\t2\nhummer\t2017-01-14\t1\nvolkswagen\t2017-01-14\t3\nland_rover\t2017-01-24\t9\ndacia\t2017-01-24\t14\nbmw\t2017-01-24\t35\nhonda\t2017-01-24\t3\nbentley\t2017-01-24\t1\nlexus\t2017-01-24\t2\nds\t2017-01-24\t3\nmercedes\t2017-01-24\t28\nmg\t2017-01-24\t1\nlancia\t2017-01-24\t2\nsmart\t2017-01-24\t4\nautres\t2017-01-24\t6\nbertone\t2017-01-24\t1\nkia\t2017-01-24\t10\nhyundai\t2017-01-24\t7\nchevrolet\t2017-01-24\t4\nchrysler\t2017-01-24\t1\nporsche\t2017-01-24\t12\njeep\t2017-01-24\t2\nvolkswagen\t2017-01-24\t45\ninfiniti\t2017-01-24\t1\nsuzuki\t2017-01-24\t3\nmitsubishi\t2017-01-24\t5\nmaserati\t2017-01-24\t1\nfiat\t2017-01-24\t30\npeugeot\t2017-01-24\t107\nseat\t2017-01-24\t17\nnissan\t2017-01-24\t25\nvolvo\t2017-01-24\t5\njaguar\t2017-01-24\t3\ntoyota\t2017-01-24\t14\nsaab\t2017-01-24\t2\ncitroen\t2017-01-24\t94\nskoda\t2017-01-24\t5\nferrari\t2017-01-24\t2\nnull\t2017-01-24\t5\nford\t2017-01-24\t18\nmini\t2017-01-24\t19\nopel\t2017-01-24\t22\nalfa_romeo\t2017-01-24\t10\nrover\t2017-01-24\t1\naudi\t2017-01-24\t45\nrenault\t2017-01-24\t95\ndodge\t2017-01-24\t1\nlotus\t2017-01-24\t1\njeep\t2017-02-03\t3\nhyundai\t2017-02-03\t6\nporsche\t2017-02-03\t7\nrenault\t2017-02-03\t125\ndacia\t2017-02-03\t7\nds\t2017-02-03\t4\nnissan\t2017-02-03\t17\nnull\t2017-02-03\t6\npeugeot\t2017-02-03\t92\nmaserati\t2017-02-03\t1\nfiat\t2017-02-03\t25\nvolvo\t2017-02-03\t7\nlancia\t2017-02-03\t3\nalfa_romeo\t2017-02-03\t6\nopel\t2017-02-03\t48\nskoda\t2017-02-03\t6\ntoyota\t2017-02-03\t7\nford\t2017-02-03\t31\naudi\t2017-02-03\t45\nmercedes\t2017-02-03\t25\nchevrolet\t2017-02-03\t5\nkia\t2017-02-03\t9\nhonda\t2017-02-03\t5\nland_rover\t2017-02-03\t3\ncitroen\t2017-02-03\t82\nmazda\t2017-02-03\t5\nmitsubishi\t2017-02-03\t4\nseat\t2017-02-03\t7\njaguar\t2017-02-03\t3\nautres\t2017-02-03\t1\nferrari\t2017-02-03\t1\nsmart\t2017-02-03\t3\nmini\t2017-02-03\t13\nbmw\t2017-02-03\t42\nsaab\t2017-02-03\t2\nsuzuki\t2017-02-03\t4\nvolkswagen\t2017-02-03\t51\n"}]},"apps":[],"jobName":"paragraph_1601895497400_-1616639859","id":"20180224-163042_1051733430","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43689"},{"text":"%md\n\n# Partie 2\n","dateUpdated":"2020-10-05T10:58:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Partie 2</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497401_-1617024608","id":"20180227-180540_263433925","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43690"},{"text":"%md\n\n## Exercice libre sur les données de leboncoin\n\n### Réutilisez votre dataframe source\n\n### Afficher (dans un DF) pour chacun des véhicules (marque, modele) le prix min, max, moyen et le nombre de véhicules vendus\n\n### Afficher dans des graphiques Zeppelin :\n- Le nombre de ventes par marque\n- Le prix moyen de vente par marque\n- L'évolution du prix moyen de vente des Renault par année\n- Le même graphique, avec en comparaison les ventes Peugeot et Citroën\n- Le prix moyen des peugeot 206 par région\n- Le nombre de km moyen des voitures par région\n\n\n### Afficher pour chacune des voitures les voitures de la même région à +/- 1K euro et 10 000km","dateUpdated":"2020-10-05T10:58:17+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Exercice libre sur les données de leboncoin</h2>\n<h3>Réutilisez votre dataframe source</h3>\n<h3>Afficher (dans un DF) pour chacun des véhicules (marque, modele) le prix min, max, moyen et le nombre de véhicules vendus</h3>\n<h3>Afficher dans des graphiques Zeppelin :</h3>\n<ul>\n  <li>Le nombre de ventes par marque</li>\n  <li>Le prix moyen de vente par marque</li>\n  <li>L&rsquo;évolution du prix moyen de vente des Renault par année</li>\n  <li>Le même graphique, avec en comparaison les ventes Peugeot et Citroën</li>\n  <li>Le prix moyen des peugeot 206 par région</li>\n  <li>Le nombre de km moyen des voitures par région</li>\n</ul>\n<h3>Afficher pour chacune des voitures les voitures de la même région à +/- 1K euro et 10 000km</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1601895497401_-1617024608","id":"20180227-180549_1493881559","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43691"},{"text":"%sql\n","dateUpdated":"2020-10-05T10:58:17+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1601895497402_-1615870361","id":"20180227-175912_1762390598","dateCreated":"2020-10-05T10:58:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:43692"}],"name":"2 - Exercices/Exercice 5 - Structured Streaming","id":"2FNRJK57G","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}